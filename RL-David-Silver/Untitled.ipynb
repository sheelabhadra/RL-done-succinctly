{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Model-Free Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte-Carlo Reinforcement Learning\n",
    "\n",
    "* MC methods learn directly from episodes of experience\n",
    "* MC is *model-free*: no knowledge of MDP transitions/rewards\n",
    "* MC learns from complete episodes\n",
    "* Value function = mean return\n",
    "* Caveat: can only apply MC to *episodic* MDPs\n",
    "    * All episodes must terminate\n",
    "   \n",
    "#### Monte-Carlo Policy Evaluation\n",
    "\n",
    "* Goal: learn $v_{\\pi}$ from epidodes of experience under policy $\\pi$\n",
    "$$S_{1}, A_{1}, R_{2}, ..., S_{k} \\sim \\pi$$\n",
    "* Monte-Carlo policy evaluation uses *empirical mean* return instead of *expected* return\n",
    "\n",
    "#### First-Visit Monte-Carlo Policy Evaluation\n",
    "\n",
    "* To evaluate state $s$\n",
    "* The first time-step $t$ that state $s$ is visited in an episode,\n",
    "* Increment counter $N(s) \\leftarrow N(s) + 1$\n",
    "* Increment total return $S(s) \\leftarrow S(s) + G_{t}$\n",
    "* Value is estimated by mean return $V(s) = S(s)/N(s)$\n",
    "* By law of large numbers, $V(s) \\rightarrow v_{\\pi}(s)$ as $N(s) \\rightarrow \\infty$\n",
    "> In this case we don't explore the whole state space and only traverse the states that can be covered under a given policy. This leads to sampling, thus reducing the search space.\n",
    "\n",
    "#### Every-Visit Monte-Carlo Policy Evaluation\n",
    "\n",
    "* To evaluate state $s$\n",
    "* Every time-step $t$ that state $s$ is visited in an episode,\n",
    "* Increment counter $N(s) \\leftarrow N(s) + 1$\n",
    "* Increment total return $S(s) \\leftarrow S(s) + G_{t}$\n",
    "* Value is estimated by mean return $V(s) = S(s)/N(s)$\n",
    "* By law of large numbers, $V(s) \\rightarrow v_{\\pi}(s)$ as $N(s) \\rightarrow \\infty$\n",
    "\n",
    "<img src=\"Figures/04-incremental-mean.png\" style=\"width: 550px;\"/>\n",
    "\n",
    "<img src=\"Figures/04-incremental-mc.png\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tamids]",
   "language": "python",
   "name": "conda-env-tamids-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
